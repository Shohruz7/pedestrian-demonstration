{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa55c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_cleaning_merging.ipynb\n",
    "#Project: Pedestrian Corridor Analysis â€” Cleaning & Merging  \n",
    "#Author: Shohruzbek Abdumuminov and Ragib Asif\n",
    "#Purpose: Parse WKT geometries, perform conservative cleaning of key columns, compute recent per-site summary metrics, spatially join count points to nearest corridor segments to inherit corridor `Category`, and save cleaned outputs into `data_clean/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae24cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely import wkt\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs('data_clean', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "471de262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts shape: (114, 113)\n",
      "Demand shape: (127277, 20)\n",
      "\n",
      "Counts columns:\n",
      " ['the_geom', 'OBJECTID', 'Loc', 'Borough', 'Street_Nam', 'From_Stree', 'To_Street', 'Iex', 'May07_AM', 'May07_PM', 'May07_MD', 'Sept07_AM', 'Sept07_PM', 'Sept07_MD', 'May08_AM', 'May08_PM', 'May08_MD', 'Sept08_AM', 'Sept08_PM', 'Sept08_MD', 'May09_AM', 'May09_PM', 'May09_MD', 'Sept09_AM', 'Sept09_PM', 'Sept09_MD', 'May10_AM', 'May10_PM', 'May10_MD', 'Sept10_AM', 'Sept10_PM', 'Sept10_MD', 'May11_AM', 'May11_PM', 'May11_MD', 'Sept11_AM', 'Sept11_PM', 'Sept11_MD', 'May12_AM', 'May12_PM', 'May12_MD', 'Sept12_AM', 'Sept12_PM', 'Sept12_MD', 'May13_AM', 'May13_PM', 'May13_MD', 'Sept13_AM', 'Sept13_PM', 'Sept13_MD', 'May14_AM', 'May14_PM', 'May14_MD', 'Sept14_AM', 'Sept14_PM', 'Sept14_MD', 'May15_AM', 'May15_PM', 'May15_MD', 'Sept15_AM', 'Sept15_PM', 'Sept15_MD', 'May16_AM', 'May16_PM', 'May16_MD', 'Sept16_AM', 'Sept16_PM', 'Sept16_MD', 'May17_AM', 'May17_PM', 'May17_MD', 'Sept17_AM', 'Sept17_PM', 'Sept17_MD', 'May18_AM', 'May18_PM', 'May18_MD', 'Sept18_AM', 'Sept18_PM', 'Sept18_MD', 'May19_AM', 'May19_PM', 'May19_MD', 'Oct20_AM', 'Oct20_PM', 'Oct20_MD', 'May21_AM', 'May21_PM', 'May21_MD', 'Oct21_AM', 'Oct21_PM', 'Oct21_MD', 'May22_AM', 'May22_pM', 'May22_MD', 'Oct22_AM', 'Oct22_PM', 'Oct22_MD', 'May23_AM', 'May23_pM', 'May23_MD', 'Oct23_AM', 'Oct23_PM', 'Oct23_MD', 'June24_AM', 'June24_PM', 'June24_MD', 'Oct24_AM', 'Oct24_PM', 'Oct24_MD', 'May25_AM', 'May25_PM', 'May25_MD']\n",
      "\n",
      "Demand columns:\n",
      " ['the_geom', 'BoroCode', 'BoroName', 'BoroCD', 'CounDist', 'AssemDist', 'StSenDist', 'CongDist', 'street', 'segmentid', 'Rank', 'PMP_ID', 'NTA2020', 'Boro', 'Category', 'NTAName', 'FEMAFldz', 'FEMAFldT', 'HrcEvac', 'SHAPE_Leng']\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "counts_path = \"../data-raw/pedestrian_counts.csv\"\n",
    "demand_path = \"../data-raw/pedestrian_demand.csv\"\n",
    "\n",
    "# Read CSVs (read as strings initially to avoid dtype inference issues)\n",
    "counts = pd.read_csv(counts_path, dtype=str)\n",
    "demand = pd.read_csv(demand_path, dtype=str)\n",
    "\n",
    "print(\"Counts shape:\", counts.shape)\n",
    "print(\"Demand shape:\", demand.shape)\n",
    "# show columns\n",
    "print(\"\\nCounts columns:\\n\", counts.columns.tolist())\n",
    "print(\"\\nDemand columns:\\n\", demand.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39750fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdf_counts: (114, 114)\n",
      "gdf_demand: (127277, 21)\n"
     ]
    }
   ],
   "source": [
    "# Parse WKT (shapely.wkt.loads) if 'the_geom' exists\n",
    "if 'the_geom' in counts.columns:\n",
    "    counts['geometry'] = counts['the_geom'].apply(lambda x: wkt.loads(x) if pd.notnull(x) else None)\n",
    "else:\n",
    "    raise ValueError(\"counts: 'the_geom' not found. Edit cell to use lat/lon if present.\")\n",
    "\n",
    "if 'the_geom' in demand.columns:\n",
    "    demand['geometry'] = demand['the_geom'].apply(lambda x: wkt.loads(x) if pd.notnull(x) else None)\n",
    "else:\n",
    "    raise ValueError(\"demand: 'the_geom' not found. Ensure demand geometry exists.\")\n",
    "\n",
    "# Convert to GeoDataFrames with WGS84\n",
    "gdf_counts = gpd.GeoDataFrame(counts.copy(), geometry='geometry', crs='EPSG:4326')\n",
    "gdf_demand = gpd.GeoDataFrame(demand.copy(), geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "print(\"gdf_counts:\", gdf_counts.shape)\n",
    "print(\"gdf_demand:\", gdf_demand.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bfb10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Street_Nam</th>\n",
       "      <th>Street_Nam_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Broadway</td>\n",
       "      <td>BROADWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>East 161st Street</td>\n",
       "      <td>EAST 161ST STREET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>East Fordham Road</td>\n",
       "      <td>EAST FORDHAM ROAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>East Gun Hill Road</td>\n",
       "      <td>EAST GUN HILL ROAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>East Tremont Avenue</td>\n",
       "      <td>EAST TREMONT AVENUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OBJECTID Loc Borough           Street_Nam     Street_Nam_clean\n",
       "0        1   1   Bronx             Broadway             BROADWAY\n",
       "1        2   2   Bronx    East 161st Street    EAST 161ST STREET\n",
       "2        3   3   Bronx    East Fordham Road    EAST FORDHAM ROAD\n",
       "3        4   4   Bronx   East Gun Hill Road   EAST GUN HILL ROAD\n",
       "4        5   5   Bronx  East Tremont Avenue  EAST TREMONT AVENUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmentid</th>\n",
       "      <th>BoroName</th>\n",
       "      <th>street</th>\n",
       "      <th>street_clean</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0055131</td>\n",
       "      <td>Queens</td>\n",
       "      <td>122 STREET</td>\n",
       "      <td>122 STREET</td>\n",
       "      <td>Community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000016</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>WARDS POINT AVENUE</td>\n",
       "      <td>WARDS POINT AVENUE</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0056031</td>\n",
       "      <td>Queens</td>\n",
       "      <td>120 STREET</td>\n",
       "      <td>120 STREET</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0180320</td>\n",
       "      <td>Queens</td>\n",
       "      <td>CROYDON ROAD</td>\n",
       "      <td>CROYDON ROAD</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008394</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>MAPLE PARKWAY</td>\n",
       "      <td>MAPLE PARKWAY</td>\n",
       "      <td>Community</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  segmentid       BoroName              street        street_clean   Category\n",
       "0   0055131         Queens          122 STREET          122 STREET  Community\n",
       "1   0000016  Staten Island  WARDS POINT AVENUE  WARDS POINT AVENUE   Baseline\n",
       "2   0056031         Queens          120 STREET          120 STREET   Baseline\n",
       "3   0180320         Queens        CROYDON ROAD        CROYDON ROAD   Baseline\n",
       "4   0008394  Staten Island       MAPLE PARKWAY       MAPLE PARKWAY  Community"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  helper\n",
    "def clean_string_series(s):\n",
    "    return s.astype(str).str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Standardize borough-like columns\n",
    "# counts sample uses 'Borough', demand sample uses 'BoroName' and 'Boro'\n",
    "# Standardize to: Brooklyn, Queens, Manhattan, Staten Island, The Bronx\n",
    "if 'Borough' in gdf_counts.columns:\n",
    "    gdf_counts['Borough'] = clean_string_series(gdf_counts['Borough']).str.title()\n",
    "    # Fix Staten Island (truncated as \"Staten Isla\")\n",
    "    gdf_counts['Borough'] = gdf_counts['Borough'].replace('Staten Isla', 'Staten Island')\n",
    "    # Fix Bronx to \"The Bronx\"\n",
    "    gdf_counts['Borough'] = gdf_counts['Borough'].replace('Bronx', 'The Bronx')\n",
    "    \n",
    "    # Assign boroughs to bridge locations based on coordinates\n",
    "    bridge_mask = gdf_counts['Borough'].isin(['East River Bridges', 'Harlem River Bridges'])\n",
    "    if bridge_mask.sum() > 0:\n",
    "        print(f\"Found {bridge_mask.sum()} bridge locations. Assigning boroughs based on coordinates...\")\n",
    "        for idx in gdf_counts[bridge_mask].index:\n",
    "            if gdf_counts.loc[idx, 'geometry'] is not None:\n",
    "                lon = gdf_counts.loc[idx, 'geometry'].centroid.x\n",
    "                lat = gdf_counts.loc[idx, 'geometry'].centroid.y\n",
    "                street_name = gdf_counts.loc[idx, 'Street_Nam'] if 'Street_Nam' in gdf_counts.columns else ''\n",
    "                assigned_borough = get_borough_from_coords(lon, lat, street_name)\n",
    "                gdf_counts.loc[idx, 'Borough'] = assigned_borough\n",
    "                print(f\"  OBJECTID {gdf_counts.loc[idx, 'OBJECTID']}: {gdf_counts.loc[idx, 'Street_Nam']} -> {assigned_borough}\")\n",
    "    \n",
    "    # Verify we have all 5 boroughs (no bridges should remain)\n",
    "    valid_boroughs = ['Brooklyn', 'Queens', 'Manhattan', 'Staten Island', 'The Bronx']\n",
    "    gdf_counts = gdf_counts[gdf_counts['Borough'].isin(valid_boroughs)].copy()\n",
    "    print(f\"\\nAfter assigning bridge locations and filtering: {len(gdf_counts)} locations\")\n",
    "    print(f\"Borough distribution: {gdf_counts['Borough'].value_counts().to_dict()}\")\n",
    "elif 'Boro' in gdf_counts.columns:\n",
    "    gdf_counts['Borough'] = clean_string_series(gdf_counts['Boro']).str.title()\n",
    "    gdf_counts['Borough'] = gdf_counts['Borough'].replace('Staten Isla', 'Staten Island')\n",
    "    gdf_counts['Borough'] = gdf_counts['Borough'].replace('Bronx', 'The Bronx')\n",
    "    \n",
    "    # Assign boroughs to bridge locations based on coordinates\n",
    "    bridge_mask = gdf_counts['Borough'].isin(['East River Bridges', 'Harlem River Bridges'])\n",
    "    if bridge_mask.sum() > 0:\n",
    "        print(f\"Found {bridge_mask.sum()} bridge locations. Assigning boroughs based on coordinates...\")\n",
    "        for idx in gdf_counts[bridge_mask].index:\n",
    "            if gdf_counts.loc[idx, 'geometry'] is not None:\n",
    "                lon = gdf_counts.loc[idx, 'geometry'].centroid.x\n",
    "                lat = gdf_counts.loc[idx, 'geometry'].centroid.y\n",
    "                street_name = gdf_counts.loc[idx, 'Street_Nam'] if 'Street_Nam' in gdf_counts.columns else ''\n",
    "                #assigned_borough = get_borough_from_coords(lon, lat, street_name)\n",
    "                #gdf_counts.loc[idx, 'Borough'] = assigned_borough\n",
    "                #print(f\"  OBJECTID {gdf_counts.loc[idx, 'OBJECTID']}: {gdf_counts.loc[idx, 'Street_Nam']} -> {assigned_borough}\")\n",
    "    \n",
    "    # Verify we have all 5 boroughs (no bridges should remain)\n",
    "    valid_boroughs = ['Brooklyn', 'Queens', 'Manhattan', 'Staten Island', 'The Bronx']\n",
    "    gdf_counts = gdf_counts[gdf_counts['Borough'].isin(valid_boroughs)].copy()\n",
    "    print(f\"\\nAfter assigning bridge locations and filtering: {len(gdf_counts)} locations\")\n",
    "    print(f\"Borough distribution: {gdf_counts['Borough'].value_counts().to_dict()}\")\n",
    "\n",
    "if 'BoroName' in gdf_demand.columns:\n",
    "    gdf_demand['BoroName'] = clean_string_series(gdf_demand['BoroName']).str.title()\n",
    "    # Handle multi-borough entries (e.g., \"Manhattan,Brooklyn\") - use first borough\n",
    "    gdf_demand['BoroName'] = gdf_demand['BoroName'].str.split(',').str[0].str.strip()\n",
    "    # Standardize to match counts\n",
    "    gdf_demand['BoroName'] = gdf_demand['BoroName'].replace('Bronx', 'The Bronx')\n",
    "    # Filter to only 5 main boroughs\n",
    "    valid_boroughs = ['Brooklyn', 'Queens', 'Manhattan', 'Staten Island', 'The Bronx']\n",
    "    gdf_demand = gdf_demand[gdf_demand['BoroName'].isin(valid_boroughs)].copy()\n",
    "    print(f\"After filtering demand to 5 boroughs: {len(gdf_demand)} segments\")\n",
    "elif 'Boro' in gdf_demand.columns:\n",
    "    gdf_demand['BoroName'] = clean_string_series(gdf_demand['Boro']).str.title()\n",
    "    gdf_demand['BoroName'] = gdf_demand['BoroName'].str.split(',').str[0].str.strip()\n",
    "    gdf_demand['BoroName'] = gdf_demand['BoroName'].replace('Bronx', 'The Bronx')\n",
    "    valid_boroughs = ['Brooklyn', 'Queens', 'Manhattan', 'Staten Island', 'The Bronx']\n",
    "    gdf_demand = gdf_demand[gdf_demand['BoroName'].isin(valid_boroughs)].copy()\n",
    "\n",
    "# Street name cleaning\n",
    "# counts uses 'Street_Nam', demand uses 'street'\n",
    "if 'Street_Nam' in gdf_counts.columns:\n",
    "    gdf_counts['Street_Nam_clean'] = clean_string_series(gdf_counts['Street_Nam']).str.upper()\n",
    "else:\n",
    "    possible = [c for c in gdf_counts.columns if 'street' in c.lower()]\n",
    "    if possible:\n",
    "        gdf_counts['Street_Nam_clean'] = clean_string_series(gdf_counts[possible[0]]).str.upper()\n",
    "    else:\n",
    "        gdf_counts['Street_Nam_clean'] = ''\n",
    "\n",
    "if 'street' in gdf_demand.columns:\n",
    "    gdf_demand['street_clean'] = clean_string_series(gdf_demand['street']).str.upper()\n",
    "else:\n",
    "    possible = [c for c in gdf_demand.columns if 'street' in c.lower()]\n",
    "    if possible:\n",
    "        gdf_demand['street_clean'] = clean_string_series(gdf_demand[possible[0]]).str.upper()\n",
    "    else:\n",
    "        gdf_demand['street_clean'] = ''\n",
    "\n",
    "# Category standardization (sample shows 'Category')\n",
    "if 'Category' in gdf_demand.columns:\n",
    "    gdf_demand['Category'] = clean_string_series(gdf_demand['Category']).str.title()\n",
    "\n",
    "# Show samples\n",
    "display(gdf_counts[['OBJECTID','Loc','Borough','Street_Nam','Street_Nam_clean']].head())\n",
    "display(gdf_demand[['segmentid','BoroName','street','street_clean','Category']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13aa908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified count columns (sample): ['May07_AM', 'May07_PM', 'May07_MD', 'Sept07_AM', 'Sept07_PM', 'Sept07_MD', 'May08_AM', 'May08_PM', 'May08_MD', 'Sept08_AM', 'Sept08_PM', 'Sept08_MD', 'May09_AM', 'May09_PM', 'May09_MD', 'Sept09_AM', 'Sept09_PM', 'Sept09_MD', 'May10_AM', 'May10_PM', 'May10_MD', 'Sept10_AM', 'Sept10_PM', 'Sept10_MD', 'May11_AM', 'May11_PM', 'May11_MD', 'Sept11_AM', 'Sept11_PM', 'Sept11_MD']\n",
      "Numeric count columns: ['May07_AM_num', 'May07_PM_num', 'May07_MD_num', 'Sept07_AM_num', 'Sept07_PM_num', 'Sept07_MD_num', 'May08_AM_num', 'May08_PM_num', 'May08_MD_num', 'Sept08_AM_num', 'Sept08_PM_num', 'Sept08_MD_num', 'May09_AM_num', 'May09_PM_num', 'May09_MD_num', 'Sept09_AM_num', 'Sept09_PM_num', 'Sept09_MD_num', 'May10_AM_num', 'May10_PM_num', 'May10_MD_num', 'Sept10_AM_num', 'Sept10_PM_num', 'Sept10_MD_num', 'May11_AM_num', 'May11_PM_num', 'May11_MD_num', 'Sept11_AM_num', 'Sept11_PM_num', 'Sept11_MD_num']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Identify columns that look like count columns (heuristic: contain month tokens and am/pm/md)\n",
    "tokens = ['may','oct','sept','jun','june','apr','mar','feb','jan','nov','dec']\n",
    "count_cols = [c for c in gdf_counts.columns if any(t in c.lower() for t in tokens) and any(x in c.lower() for x in ['am','pm','md'])]\n",
    "# fallback: detect columns with many numeric-looking entries\n",
    "if not count_cols:\n",
    "    numeric_candidates = []\n",
    "    for c in gdf_counts.columns:\n",
    "        # try to coerce some values\n",
    "        sample = gdf_counts[c].dropna().astype(str).str.replace(',','').head(50)\n",
    "        coerced = pd.to_numeric(sample, errors='coerce')\n",
    "        if coerced.notna().sum() > 5:\n",
    "            numeric_candidates.append(c)\n",
    "    count_cols = numeric_candidates\n",
    "\n",
    "print(\"Identified count columns (sample):\", count_cols[:30])\n",
    "\n",
    "# Convert to numeric (remove commas if present)\n",
    "for c in count_cols:\n",
    "    gdf_counts[c+'_num'] = pd.to_numeric(gdf_counts[c].str.replace(',',''), errors='coerce')\n",
    "\n",
    "# List numeric columns created\n",
    "num_cols = [c for c in gdf_counts.columns if c.endswith('_num')]\n",
    "print(\"Numeric count columns:\", num_cols[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3edd8a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using recent columns: ['June24_AM_num', 'June24_PM_num', 'June24_MD_num', 'Oct24_AM_num', 'Oct24_PM_num', 'Oct24_MD_num', 'May25_AM_num', 'May25_PM_num', 'May25_MD_num']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Street_Nam_clean</th>\n",
       "      <th>avg_recent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BROADWAY</td>\n",
       "      <td>2138.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>EAST 161ST STREET</td>\n",
       "      <td>2964.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>EAST FORDHAM ROAD</td>\n",
       "      <td>4018.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EAST GUN HILL ROAD</td>\n",
       "      <td>1535.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>EAST TREMONT AVENUE</td>\n",
       "      <td>1370.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OBJECTID Loc     Street_Nam_clean  avg_recent_count\n",
       "0        1   1             BROADWAY       2138.555556\n",
       "1        2   2    EAST 161ST STREET       2964.555556\n",
       "2        3   3    EAST FORDHAM ROAD       4018.111111\n",
       "3        4   4   EAST GUN HILL ROAD       1535.777778\n",
       "4        5   5  EAST TREMONT AVENUE       1370.111111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count      114.000000\n",
       "mean      2934.093567\n",
       "std       2659.981127\n",
       "min          0.000000\n",
       "25%       1136.305556\n",
       "50%       2230.055556\n",
       "75%       3908.750000\n",
       "max      13352.333333\n",
       "Name: avg_recent_count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Heuristic: prefer columns containing '24' or '25' as most recent\n",
    "recent_cols = [c for c in num_cols if ('24' in c or '25' in c)]\n",
    "if recent_cols:\n",
    "    print(\"Using recent columns:\", recent_cols)\n",
    "    gdf_counts['avg_recent_count'] = gdf_counts[recent_cols].astype(float).mean(axis=1, skipna=True)\n",
    "else:\n",
    "    print(\"No explicit 24/25 columns found; using all numeric count cols for mean.\")\n",
    "    gdf_counts['avg_recent_count'] = gdf_counts[num_cols].astype(float).mean(axis=1, skipna=True)\n",
    "\n",
    "# Examine results\n",
    "display(gdf_counts[['OBJECTID','Loc','Street_Nam_clean','avg_recent_count']].head())\n",
    "gdf_counts['avg_recent_count'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a52aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined shape: (155, 226)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Street_Nam_clean</th>\n",
       "      <th>segmentid</th>\n",
       "      <th>street_clean</th>\n",
       "      <th>Category</th>\n",
       "      <th>dist_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BROADWAY</td>\n",
       "      <td>0079707</td>\n",
       "      <td>BROADWAY</td>\n",
       "      <td>Regional</td>\n",
       "      <td>0.125303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>EAST 161ST STREET</td>\n",
       "      <td>0313939</td>\n",
       "      <td>EAST 161 STREET</td>\n",
       "      <td>Regional</td>\n",
       "      <td>1.417309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>EAST FORDHAM ROAD</td>\n",
       "      <td>0080043</td>\n",
       "      <td>EAST FORDHAM ROAD</td>\n",
       "      <td>Regional</td>\n",
       "      <td>1.110133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EAST GUN HILL ROAD</td>\n",
       "      <td>0081299</td>\n",
       "      <td>EAST GUN HILL ROAD</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.835461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>EAST TREMONT AVENUE</td>\n",
       "      <td>0078822</td>\n",
       "      <td>EAST TREMONT AVENUE</td>\n",
       "      <td>Regional</td>\n",
       "      <td>0.329976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>GRA CONCOURSE</td>\n",
       "      <td>0314755</td>\n",
       "      <td>GRAND CONCOURSE</td>\n",
       "      <td>Regional</td>\n",
       "      <td>0.330675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>THIRD AVENUE</td>\n",
       "      <td>0070202</td>\n",
       "      <td>3 AVENUE</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>1.364945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>WHITE PLAINS ROAD</td>\n",
       "      <td>0087453</td>\n",
       "      <td>WHITE PLAINS ROAD</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>1.818604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5TH AVENUE</td>\n",
       "      <td>0020712</td>\n",
       "      <td>5 AVENUE</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.001692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5TH AVENUE</td>\n",
       "      <td>0022891</td>\n",
       "      <td>5 AVENUE</td>\n",
       "      <td>Regional</td>\n",
       "      <td>0.068242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OBJECTID Loc     Street_Nam_clean segmentid         street_clean  \\\n",
       "0        1   1             BROADWAY   0079707             BROADWAY   \n",
       "1        2   2    EAST 161ST STREET   0313939      EAST 161 STREET   \n",
       "2        3   3    EAST FORDHAM ROAD   0080043    EAST FORDHAM ROAD   \n",
       "3        4   4   EAST GUN HILL ROAD   0081299   EAST GUN HILL ROAD   \n",
       "4        5   5  EAST TREMONT AVENUE   0078822  EAST TREMONT AVENUE   \n",
       "5        6   6        GRA CONCOURSE   0314755      GRAND CONCOURSE   \n",
       "6        7   7         THIRD AVENUE   0070202             3 AVENUE   \n",
       "7        8   8    WHITE PLAINS ROAD   0087453    WHITE PLAINS ROAD   \n",
       "8        9   9           5TH AVENUE   0020712             5 AVENUE   \n",
       "9       10  10           5TH AVENUE   0022891             5 AVENUE   \n",
       "\n",
       "       Category    dist_m  \n",
       "0      Regional  0.125303  \n",
       "1      Regional  1.417309  \n",
       "2      Regional  1.110133  \n",
       "3  Neighborhood  0.835461  \n",
       "4      Regional  0.329976  \n",
       "5      Regional  0.330675  \n",
       "6  Neighborhood  1.364945  \n",
       "7  Neighborhood  1.818604  \n",
       "8  Neighborhood  0.001692  \n",
       "9      Regional  0.068242  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Project to metric CRS for distance calc (Web Mercator 3857)\n",
    "gdf_counts = gdf_counts.set_geometry('geometry').to_crs(epsg=3857)\n",
    "gdf_demand = gdf_demand.set_geometry('geometry').to_crs(epsg=3857)\n",
    "\n",
    "# Keep minimal demand cols\n",
    "demand_small = gdf_demand[['segmentid','street_clean','Category','geometry']].copy()\n",
    "\n",
    "# sjoin_nearest to attach nearest corridor segment info\n",
    "# geopandas.sjoin_nearest requires geopandas >= 0.10\n",
    "joined = gpd.sjoin_nearest(gdf_counts, demand_small, how='left', distance_col='dist_m')\n",
    "\n",
    "# Deduplicate: keep only the nearest match for each count location\n",
    "# Some locations may match multiple segments at equal distance\n",
    "joined = joined.sort_values('dist_m').drop_duplicates(subset=['OBJECTID'], keep='first')\n",
    "\n",
    "print(\"Joined shape:\", joined.shape)\n",
    "print(f\"Unique OBJECTID count: {joined['OBJECTID'].nunique()}\")\n",
    "display(joined[['OBJECTID','Loc','Street_Nam_clean','segmentid','street_clean','Category','dist_m']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of count sites matched to a corridor category: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    155.000000\n",
       "mean      42.384192\n",
       "std      100.824071\n",
       "min        0.000122\n",
       "25%        0.031999\n",
       "50%        0.383165\n",
       "75%        4.215477\n",
       "max      453.254574\n",
       "Name: dist_m, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Category</th>\n",
       "      <th>dist_m</th>\n",
       "      <th>near_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>Global</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>Global</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>Global</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>Global</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>Global</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>Global</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>Regional</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>Regional</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>Global</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Global</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID Loc      Category    dist_m  near_match_flag\n",
       "10       11  11  Neighborhood  0.000122            False\n",
       "63       64  64        Global  0.000454            False\n",
       "63       64  64        Global  0.000454            False\n",
       "33       34  34  Neighborhood  0.000563            False\n",
       "16       17  17  Neighborhood  0.000683            False\n",
       "68       69  69        Global  0.000700            False\n",
       "64       65  65        Global  0.000835            False\n",
       "67       68  68        Global  0.000945            False\n",
       "67       68  68        Global  0.000945            False\n",
       "93       94  94  Neighborhood  0.001109            False\n",
       "59       60  60      Regional  0.001202            False\n",
       "49       50  50      Regional  0.001275            False\n",
       "48       49  49        Global  0.001347            False\n",
       "38       39  39  Neighborhood  0.001449            False\n",
       "13       14  14        Global  0.001540            False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many matched to a Category?\n",
    "joined['has_category'] = joined['Category'].notna()\n",
    "pct_joined = joined['has_category'].mean() * 100\n",
    "print(f\"Percent of count sites matched to a corridor category: {pct_joined:.1f}%\")\n",
    "\n",
    "# Verify we have all 5 categories\n",
    "all_categories = ['Global', 'Regional', 'Neighborhood', 'Community', 'Baseline']\n",
    "categories_found = joined['Category'].unique()\n",
    "print(f\"\\nCategories found: {sorted(categories_found)}\")\n",
    "print(f\"Expected 5 categories: {all_categories}\")\n",
    "for cat in all_categories:\n",
    "    count = (joined['Category'] == cat).sum()\n",
    "    print(f\"  {cat}: {count} locations\")\n",
    "\n",
    "# Verify we have all 5 boroughs\n",
    "all_boroughs = ['Brooklyn', 'Queens', 'Manhattan', 'Staten Island', 'The Bronx']\n",
    "boroughs_found = joined['Borough'].unique()\n",
    "print(f\"\\nBoroughs found: {sorted(boroughs_found)}\")\n",
    "print(f\"Expected 5 boroughs: {all_boroughs}\")\n",
    "for boro in all_boroughs:\n",
    "    count = (joined['Borough'] == boro).sum()\n",
    "    print(f\"  {boro}: {count} locations\")\n",
    "\n",
    "# Distance distribution\n",
    "display(joined['dist_m'].describe())\n",
    "\n",
    "# Flag distant matches for manual review (e.g., > 100 m)\n",
    "threshold_m = 100\n",
    "joined['near_match_flag'] = joined['dist_m'] > threshold_m\n",
    "display(joined[['OBJECTID','Loc','Borough','Category','dist_m','near_match_flag']].sort_values('dist_m').head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to WGS84 for saving\n",
    "out_gdf = joined.to_crs(epsg=4326)\n",
    "\n",
    "# CSV of key columns\n",
    "out_csv = 'data_clean/pedestrian_combined.csv'\n",
    "cols_to_save = ['OBJECTID','Loc','Borough','Street_Nam_clean','avg_recent_count','segmentid','street_clean','Category','dist_m']\n",
    "# Some columns might be missing if names differ; keep what exists\n",
    "cols_to_save = [c for c in cols_to_save if c in out_gdf.columns]\n",
    "out_gdf[cols_to_save].to_csv(out_csv, index=False)\n",
    "print(\"Saved CSV:\", out_csv)\n",
    "\n",
    "# GeoJSON for mapping\n",
    "out_geo = 'data_clean/pedestrian_combined.geojson'\n",
    "out_gdf.to_file(out_geo, driver='GeoJSON')\n",
    "print(\"Saved GeoJSON:\", out_geo)\n",
    "# End of notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12db52e",
   "metadata": {},
   "source": [
    "## Next steps / Notes\n",
    "\n",
    "- Inspect rows flagged with `near_match_flag == True`. If there are many, we can consider these:\n",
    "  - Increasing threshold \n",
    "  - Using fuzzy name matching (thefuzz) comparing `Street_Nam_clean` with `street_clean`.\n",
    "- If `avg_recent_count` is NaN for many sites, revisit `count_cols` detection and ensure numeric conversion succeeded.\n",
    "- Commit `data_clean/pedestrian_combined.csv` to your `analysis` branch when validated.\n",
    "- Later: load this CSV into SQL Server or push via SQLAlchemy to make it available to the dashboard backend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
